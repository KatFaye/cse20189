Lab 10 Report
============

Author: Kat Herring

In order to use the data processing program, the user simply inputs two plain-text files (without the .txt extension) and two output files, one with the count of the unique words and one with a list of the words in the documents and how often they were used.

Internally, the program requests then receives the input of two file names, which are then converted to a c_str() and opened using fstream.

The program checks if the file is open, and if it is, uses getline() to get lines from a file while the file is still good. Punctuation is striped using line.erase() and ispunct(), and all letters are converted to lowercase using tolower(). This is then piped into a temporary outFile.

This temp file is then used to create the map of words, reading in space-delimited strings. When this is finished, the number of unique words is stored using size(), and an output list of unique words and times used is generated by iterating over wordCounts and piping that into a file.

All files are closed, and the temporary file is deleted.

I verified this program for correctness by running it with two test text files and checking if the output was what was expected.

My dictionaries used for the language guessing program each had 250 of the most common words, which I considered ideal because it was a reasonable amount to check for no crossovers and typos. Past a certain dictionary size, the guesses will not get more accurate.

Neither option seemed natural for the Sudoku problem, as I discovered I'd programmed my original Sudoku puzzle differently than most students. However, the vector methods make much more sense to me and were far easier to code.

C++11 in general, however, is easier to use for many aspects of the programs, particularly the Jaccard one and the data processor.
